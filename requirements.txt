"""
Smart Backup - Backup Engine
Tarih: 19 KasÄ±m 2025
Yazar: Dr. Mustafa AfyonluoÄŸlu

customtkinter==5.2.2
    """Yedekleme iÅŸlemlerini gerÃ§ekleÅŸtiren motor sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        self.cancelled = False
        self.progress_callback = None
        self.status_callback = None
    
    def set_progress_callback(self, callback: Callable[[float], None]):
        """Ä°lerleme callback'ini ayarla
        
        Args:
            callback: Ä°lerleme yÃ¼zdesi alan fonksiyon (0.0 - 1.0)
        """
        self.progress_callback = callback
    
    def set_status_callback(self, callback: Callable[[str], None]):
        """Durum mesajÄ± callback'ini ayarla
        
        Args:
            callback: Durum mesajÄ± alan fonksiyon
        """
        self.status_callback = callback
    
    def cancel(self):
        """Ä°ÅŸlemi iptal et"""
        self.cancelled = True
    
    def reset_cancel(self):
        """Ä°ptal bayraÄŸÄ±nÄ± sÄ±fÄ±rla"""
        self.cancelled = False
    
    def get_files_from_mapping(self, source_path: str, file_filter: str, 
                               exclude_filter: str, include_subdirs: bool) -> List[str]:
        """EÅŸleÅŸmeye gÃ¶re dosya listesi oluÅŸtur
        
        Args:
            source_path: Kaynak klasÃ¶r
            file_filter: Dosya filtresi (Ã¶rn: *.*, *.doc*, abc*.txt veya virgÃ¼lle ayrÄ±lmÄ±ÅŸ: *.py, *.txt)
            exclude_filter: HariÃ§ tutulacak dosya filtresi (Ã¶rn: *.db, temp\\*.* )
            include_subdirs: Alt klasÃ¶rleri dahil et
            
        Returns:
            Dosya yollarÄ±nÄ±n listesi
        """
        files = []
        
        # Yolu normalize et ve kontrol et
        source_path = os.path.normpath(source_path)
        
        if not os.path.exists(source_path):
            if self.status_callback:
                self.status_callback(f"UYARI: Kaynak klasÃ¶r bulunamadÄ±: {source_path}")
            return files
        
        if not os.path.isdir(source_path):
            if self.status_callback:
                self.status_callback(f"UYARI: Kaynak yol bir klasÃ¶r deÄŸil: {source_path}")
            return files
        
        # File filter'Ä± virgÃ¼lle ayÄ±r (birden fazla pattern destekle)
        filter_patterns = [p.strip() for p in file_filter.split(',') if p.strip()]
        if not filter_patterns:
            filter_patterns = ['*.*']  # VarsayÄ±lan: tÃ¼m dosyalar
        
        # Her pattern iÃ§in dosyalarÄ± topla
        all_files = set()  # Tekrar etmemeleri iÃ§in set kullan
        for pattern in filter_patterns:
            if include_subdirs:
                # Alt klasÃ¶rler dahil
                full_pattern = os.path.join(source_path, '**', pattern)
                matched = glob.glob(full_pattern, recursive=True)
            else:
                # Sadece ana klasÃ¶r
                full_pattern = os.path.join(source_path, pattern)
                matched = glob.glob(full_pattern, recursive=False)
            
            all_files.update(matched)
        
        # Sadece dosyalarÄ± al (klasÃ¶rleri deÄŸil)
        files = [f for f in all_files if os.path.isfile(f)]
        
        # Exclude filter uygula
        if exclude_filter:
            files = self._apply_exclude_filter(files, source_path, exclude_filter, include_subdirs)
        
        return files
    
    def _apply_exclude_filter(self, files: List[str], source_path: str, 
                              exclude_filter: str, include_subdirs: bool) -> List[str]:
        """Exclude filter uygula
        
        Args:
            files: Dosya listesi
            source_path: Kaynak klasÃ¶r
            exclude_filter: HariÃ§ tutulacak dosya filtresi (virgÃ¼lle ayrÄ±lmÄ±ÅŸ)
                          Pattern Ã¶rnekleri:
                          - "*.zip" -> tÃ¼m zip dosyalarÄ±  
                          - "__pycache__\\*.*" -> her seviyedeki __pycache__ klasÃ¶rÃ¼ (recursive modda)
                          - "temp\\*.*" -> temp klasÃ¶rÃ¼ndeki tÃ¼m dosyalar (relative)
                          - "**\\*.log" -> tÃ¼m alt klasÃ¶rlerdeki log dosyalarÄ± (explicit)
                          - "SmartBackup\\TEST_MAIN\\*.*" -> belirli klasÃ¶rdeki dosyalar
            include_subdirs: Alt klasÃ¶rleri dahil et
            
        Returns:
            FiltrelenmiÅŸ dosya listesi
        """
        if not exclude_filter:
            return files
        
        # VirgÃ¼lle ayrÄ±lmÄ±ÅŸ filtreleri ayÄ±r
        exclude_patterns = [p.strip() for p in exclude_filter.split(',') if p.strip()]
        
        excluded_files = set()
        
        for pattern in exclude_patterns:
            # Tam yol mu yoksa relative pattern mÄ± kontrol et
            if os.path.isabs(pattern) or ':' in pattern:
                # Tam yol - direkt glob kullan
                matched = glob.glob(pattern, recursive=True)
            else:
                # Relative pattern - source_path'e ekle
                if '**' in pattern:
                    # Zaten ** var, direkt ekle
                    full_pattern = os.path.join(source_path, pattern)
                    matched = glob.glob(full_pattern, recursive=True)
                else:
                    # ** yok
                    if include_subdirs:
                        # Alt klasÃ¶rlerde ara - ** ekle
                        # Ã–rnek: "__pycache__\*.*" -> "source_path\**\__pycache__\*.*"
                        # Bu her seviyedeki __pycache__ klasÃ¶rlerini bulur
                        full_pattern = os.path.join(source_path, '**', pattern)
                        matched = glob.glob(full_pattern, recursive=True)
                    else:
                        # Sadece direkt alt klasÃ¶rde
                        full_pattern = os.path.join(source_path, pattern)
                        matched = glob.glob(full_pattern, recursive=False)
            
            excluded_files.update(matched)
        
        # HariÃ§ tutulanlarÄ± Ã§Ä±kar
        return [f for f in files if f not in excluded_files]
    
    def calculate_mapping_stats(self, source_path: str, file_filter: str,
                                exclude_filter: str, include_subdirs: bool) -> Tuple[int, int, int, int]:
        """EÅŸleÅŸme istatistiklerini hesapla
        
        Args:
            source_path: Kaynak klasÃ¶r
            file_filter: Dosya filtresi
            exclude_filter: HariÃ§ tutulacak dosya filtresi
            include_subdirs: Alt klasÃ¶rleri dahil et
            
        Returns:
            (dosya_sayÄ±sÄ±, toplam_boyut, hariÃ§_tutulan_sayÄ±, hariÃ§_tutulan_boyut) tuple'Ä±
        """
        if self.status_callback:
            self.status_callback(f"Analiz ediliyor: {source_path}")
        
        # Yolu normalize et
        source_path = os.path.normpath(source_path)
        
        # Ã–nce tÃ¼m dosyalarÄ± al (exclude olmadan) - get_files_from_mapping ile aynÄ± mantÄ±kla
        filter_patterns = [p.strip() for p in file_filter.split(',') if p.strip()]
        if not filter_patterns:
            filter_patterns = ['*.*']
        
        all_files_set = set()
        for pattern in filter_patterns:
            if include_subdirs:
                full_pattern = os.path.join(source_path, '**', pattern)
                matched = glob.glob(full_pattern, recursive=True)
            else:
                full_pattern = os.path.join(source_path, pattern)
                matched = glob.glob(full_pattern, recursive=False)
            all_files_set.update(matched)
        
        all_files = [f for f in all_files_set if os.path.isfile(f)]
        
        # Gizli klasÃ¶rlerdeki dosyalarÄ± da say
        hidden_files_count = 0
        hidden_files_size = 0
        
        if include_subdirs:
            for root, dirs, filenames in os.walk(source_path):
                for dirname in dirs[:]:
                    if dirname.startswith('.'):
                        hidden_dir_path = os.path.join(root, dirname)
                        for hidden_root, _, hidden_filenames in os.walk(hidden_dir_path):
                            for hidden_file in hidden_filenames:
                                hidden_file_path = os.path.join(hidden_root, hidden_file)
                                if os.path.isfile(hidden_file_path):
                                    hidden_files_count += 1
                                    try:
                                        hidden_files_size += os.path.getsize(hidden_file_path)
                                    except:
                                        pass
                        dirs.remove(dirname)
        
        # Sonra exclude'lu dosyalarÄ± al
        files = self.get_files_from_mapping(source_path, file_filter, exclude_filter, include_subdirs)
        
        # HariÃ§ tutulanlarÄ± bul
        excluded_files = [f for f in all_files if f not in files]
        
        total_size = sum(os.path.getsize(f) for f in files if os.path.exists(f))
        excluded_size = sum(os.path.getsize(f) for f in excluded_files if os.path.exists(f)) + hidden_files_size
        
        return len(files), total_size, len(excluded_files) + hidden_files_count, excluded_size
    
    def analyze_mapping(self, source_path: str, file_filter: str,
                       exclude_filter: str, include_subdirs: bool, target_path: str) -> Tuple[int, int, int, int]:
        """EÅŸleÅŸme iÃ§in yedeklenecek dosyalarÄ± analiz et
        
        Args:
            source_path: Kaynak klasÃ¶r
            file_filter: Dosya filtresi
            exclude_filter: HariÃ§ tutulacak dosya filtresi
            include_subdirs: Alt klasÃ¶rleri dahil et
            target_path: Hedef klasÃ¶r
            
        Returns:
            (yedeklenecek_dosya_sayÄ±sÄ±, yedeklenecek_toplam_boyut, hariÃ§_tutulan_sayÄ±, hariÃ§_tutulan_boyut) tuple'Ä±
        """
        # Yolu normalize et
        source_path = os.path.normpath(source_path)
        target_path = os.path.normpath(target_path)
        
        # Ã–nce tÃ¼m dosyalarÄ± al (exclude olmadan) - get_files_from_mapping ile aynÄ± mantÄ±kla
        filter_patterns = [p.strip() for p in file_filter.split(',') if p.strip()]
        if not filter_patterns:
            filter_patterns = ['*.*']
        
        all_files_set = set()
        for pattern in filter_patterns:
            if include_subdirs:
                full_pattern = os.path.join(source_path, '**', pattern)
                matched = glob.glob(full_pattern, recursive=True)
            else:
                full_pattern = os.path.join(source_path, pattern)
                matched = glob.glob(full_pattern, recursive=False)
            all_files_set.update(matched)
        
        all_files = [f for f in all_files_set if os.path.isfile(f)]
        
        # Sonra exclude'lu dosyalarÄ± al
        files = self.get_files_from_mapping(source_path, file_filter, exclude_filter, include_subdirs)
        
        # HariÃ§ tutulanlarÄ± bul
        excluded_files = [f for f in all_files if f not in files]
        excluded_size = sum(os.path.getsize(f) for f in excluded_files if os.path.exists(f))
        
        files_to_backup = []
        total_size = 0
        
        for source_file in files:
            if not os.path.exists(source_file):
                continue
            
            # Hedef dosya yolunu oluÅŸtur
            rel_path = os.path.relpath(source_file, source_path)
            target_file = os.path.join(target_path, rel_path)
            
            # Hedefte yoksa veya daha yeni ise yedekle
            if not os.path.exists(target_file):
                files_to_backup.append(source_file)
                total_size += os.path.getsize(source_file)
            else:
                # Tarih karÅŸÄ±laÅŸtÄ±rmasÄ±
                source_mtime = os.path.getmtime(source_file)
                target_mtime = os.path.getmtime(target_file)
                if source_mtime > target_mtime:
                    files_to_backup.append(source_file)
                    total_size += os.path.getsize(source_file)
        
        return len(files_to_backup), total_size, len(excluded_files), excluded_size
    
    def analyze_mapping_detailed(self, source_path: str, file_filter: str,
                                 exclude_filter: str, include_subdirs: bool, target_path: str) -> Dict:
        """EÅŸleÅŸme iÃ§in yedeklenecek dosyalarÄ± detaylÄ± analiz et
        
        Args:
            source_path: Kaynak klasÃ¶r
            file_filter: Dosya filtresi
            exclude_filter: HariÃ§ tutulacak dosya filtresi
            include_subdirs: Alt klasÃ¶rleri dahil et
            target_path: Hedef klasÃ¶r
            
        Returns:
            {
                'files_to_backup': [dosya_listesi],
                'excluded_count': hariÃ§_tutulan_dosya_sayÄ±sÄ±,
                'skipped_count': atlanan_dosya_sayÄ±sÄ±,
                'total_size': toplam_boyut,
                'excluded_size': hariÃ§_tutulan_boyut,
                'skipped_size': atlanan_dosya_boyutu
            }
        """
        # Yolu normalize et
        source_path = os.path.normpath(source_path)
        target_path = os.path.normpath(target_path)
        
        # Ã–nce glob ile bulunan dosyalarÄ± al (exclude olmadan)
        filter_patterns = [p.strip() for p in file_filter.split(',') if p.strip()]
        if not filter_patterns:
            filter_patterns = ['*.*']
        
        all_files_set = set()
        for pattern in filter_patterns:
            if include_subdirs:
                full_pattern = os.path.join(source_path, '**', pattern)
                matched = glob.glob(full_pattern, recursive=True)
            else:
                full_pattern = os.path.join(source_path, pattern)
                matched = glob.glob(full_pattern, recursive=False)
            all_files_set.update(matched)
        
        all_files = [f for f in all_files_set if os.path.isfile(f)]
        
        # Gizli klasÃ¶rlerdeki dosyalarÄ± da say (glob bunlarÄ± atlar)
        # .git, .vscode gibi klasÃ¶rler glob tarafÄ±ndan gÃ¶rmezden gelinir
        hidden_files_count = 0
        hidden_files_size = 0
        
        if include_subdirs:
            # os.walk ile tÃ¼m dosyalarÄ± tara (gizli klasÃ¶rler dahil)
            for root, dirs, filenames in os.walk(source_path):
                # Gizli klasÃ¶rleri kontrol et
                for dirname in dirs[:]:  # [:] ile kopya oluÅŸtur, gÃ¼venli silme iÃ§in
                    if dirname.startswith('.'):
                        # Gizli klasÃ¶r - dosyalarÄ±nÄ± say
                        hidden_dir_path = os.path.join(root, dirname)
                        for hidden_root, _, hidden_filenames in os.walk(hidden_dir_path):
                            for hidden_file in hidden_filenames:
                                hidden_file_path = os.path.join(hidden_root, hidden_file)
                                if os.path.isfile(hidden_file_path):
                                    hidden_files_count += 1
                                    try:
                                        hidden_files_size += os.path.getsize(hidden_file_path)
                                    except:
                                        pass
                        # Bu klasÃ¶re girme (zaten saydÄ±k)
                        dirs.remove(dirname)
        
        # Sonra exclude'lu dosyalarÄ± al
        files = self.get_files_from_mapping(source_path, file_filter, exclude_filter, include_subdirs)
        
        # HariÃ§ tutulanlarÄ± say (dosya listesi tutmadan)
        # Glob tarafÄ±ndan bulunan ama exclude edilen dosyalar + gizli klasÃ¶rdeki dosyalar
        excluded_files_set = set(all_files) - set(files)
        excluded_count = len(excluded_files_set) + hidden_files_count
        excluded_size = sum(os.path.getsize(f) for f in excluded_files_set if os.path.exists(f)) + hidden_files_size
        
        # _REVISIONS klasÃ¶rÃ¼ndeki dosyalarÄ± say
        revision_count = 0
        revision_size = 0
        revisions_path = os.path.join(target_path, '_REVISIONS')
        
        if os.path.exists(revisions_path):
            try:
                for root, dirs, filenames in os.walk(revisions_path):
                    for filename in filenames:
                        file_path = os.path.join(root, filename)
                        if os.path.isfile(file_path):
                            revision_count += 1
                            try:
                                revision_size += os.path.getsize(file_path)
                            except:
                                pass
            except Exception as e:
                # EriÅŸim hatasÄ± durumunda sessizce devam et
                pass
        
        files_to_backup = []
        total_size = 0
        skipped_count = 0
        skipped_size = 0
        
        # Ä°lerleme mesajÄ±
        # if self.status_callback:
        #    self.status_callback(f"ðŸŸ¢ : {source_path} : {len(files)} dosya kontrol ediliyor...")

        for source_file in files:
            if not os.path.exists(source_file):
                continue
            
            file_size = os.path.getsize(source_file)
            
            # Hedef dosya yolunu oluÅŸtur
            rel_path = os.path.relpath(source_file, source_path)
            target_file = os.path.join(target_path, rel_path)
            
            # Hedefte yoksa veya daha yeni ise yedekle
            if not os.path.exists(target_file):
                files_to_backup.append(source_file)
                total_size += file_size
            else:
                # Tarih karÅŸÄ±laÅŸtÄ±rmasÄ±
                source_mtime = os.path.getmtime(source_file)
                target_mtime = os.path.getmtime(target_file)
                if source_mtime > target_mtime:
                    files_to_backup.append(source_file)
                    total_size += file_size
                else:
                    # Dosya gÃ¼ncel, atlandÄ±
                    skipped_count += 1
                    skipped_size += file_size
        
        return {
            'files_to_backup': files_to_backup,
            'excluded_count': excluded_count,
            'skipped_count': skipped_count,
            'total_size': total_size,
            'excluded_size': excluded_size,
            'skipped_size': skipped_size,
            'revision_count': revision_count,
            'revision_size': revision_size
        }
    
    def backup_mapping(self, source_path: str, file_filter: str,
                      exclude_filter: str, include_subdirs: bool, target_path: str) -> Dict:
        """Tek bir eÅŸleÅŸme iÃ§in yedekleme yap
        
        Args:
            source_path: Kaynak klasÃ¶r
            file_filter: Dosya filtresi
            exclude_filter: HariÃ§ tutulacak dosya filtresi
            include_subdirs: Alt klasÃ¶rleri dahil et
            target_path: Hedef klasÃ¶r
            
        Returns:
            {
                'files_copied': int,
                'files_moved_to_revisions': int,
                'files_skipped': int,
                'size_copied': int,
                'size_moved': int,
                'size_skipped': int
            }
        """
        stats = {
            'files_copied': 0,
            'files_moved_to_revisions': 0,
            'files_skipped': 0,
            'size_copied': 0,
            'size_moved': 0,
            'size_skipped': 0
        }
        
        files = self.get_files_from_mapping(source_path, file_filter, exclude_filter, include_subdirs)
        
        for source_file in files:
            if self.cancelled:
                break
            
            if not os.path.exists(source_file):
                continue
            
            # Hedef dosya yolunu oluÅŸtur
            rel_path = os.path.relpath(source_file, source_path)
            target_file = os.path.join(target_path, rel_path)
            
            # Dosya boyutu
            file_size = os.path.getsize(source_file)
            
            # Hedef klasÃ¶rÃ¼ oluÅŸtur
            os.makedirs(os.path.dirname(target_file), exist_ok=True)
            
            # Hedefte dosya var mÄ± kontrol et
            if os.path.exists(target_file):
                source_mtime = os.path.getmtime(source_file)
                target_mtime = os.path.getmtime(target_file)
                
                if source_mtime > target_mtime:
                    # Hedef dosya daha eski, REVISIONS'a taÅŸÄ±
                    revision_folder = self._create_revision_folder(target_path)
                    revision_file = os.path.join(revision_folder, rel_path)
                    
                    # Revision klasÃ¶rÃ¼nÃ¼ oluÅŸtur
                    print(f"Creating revision folder: {os.path.dirname(revision_file)}")
                    os.makedirs(os.path.dirname(revision_file), exist_ok=True)
                    
                    # Eski dosyayÄ± taÅŸÄ±
                    shutil.move(target_file, revision_file)
                    stats['files_moved_to_revisions'] += 1
                    stats['size_moved'] += file_size
                    
                    # Yeni dosyayÄ± kopyala
                    shutil.copy2(source_file, target_file)
                    stats['files_copied'] += 1
                    stats['size_copied'] += file_size
                    
                    if self.status_callback:
                        size_str = self.format_size(file_size)
                        self.status_callback(f"âœ“ KopyalandÄ± (eski sÃ¼rÃ¼m arÅŸivlendi): {os.path.basename(source_file)} ({size_str})")
                else:
                    # Dosyalar aynÄ± veya hedef daha yeni, atla
                    stats['files_skipped'] += 1
                    stats['size_skipped'] += file_size
                    
                    if self.status_callback:
                        size_str = self.format_size(file_size)
                        # Mustafa self.status_callback(f"â—‹ AtlandÄ± (deÄŸiÅŸiklik yok): {os.path.basename(source_file)} ({size_str})")
            else:
                # Hedefte dosya yok, direkt kopyala
                shutil.copy2(source_file, target_file)
                stats['files_copied'] += 1
                stats['size_copied'] += file_size
                
                if self.status_callback:
                    size_str = self.format_size(file_size)
                    self.status_callback(f"âœ“ KopyalandÄ± (yeni): {os.path.basename(source_file)} ({size_str})")
        
        return stats
    
    def backup_from_analysis(self, source_path: str, target_path: str, 
                            files_to_backup: List[str]) -> Dict:
        """Analiz sonuÃ§larÄ±na gÃ¶re yedekleme yap (dosyalarÄ± tekrar taramadan)
        
        Args:
            source_path: Kaynak klasÃ¶r
            target_path: Hedef klasÃ¶r
            files_to_backup: Yedeklenecek dosya listesi (analiz sonucundan)
            
        Returns:
            {
                'files_copied': int,
                'files_moved_to_revisions': int,
                'files_skipped': int,
                'size_copied': int,
                'size_moved': int,
                'size_skipped': int
            }
        """
        stats = {
            'files_copied': 0,
            'files_moved_to_revisions': 0,
            'files_skipped': 0,
            'size_copied': 0,
            'size_moved': 0,
            'size_skipped': 0
        }
        
        for source_file in files_to_backup:
            if self.cancelled:
                break
            
            if not os.path.exists(source_file):
                continue
            
            # Hedef dosya yolunu oluÅŸtur
            rel_path = os.path.relpath(source_file, source_path)
            target_file = os.path.join(target_path, rel_path)
            
            # Dosya boyutu
            file_size = os.path.getsize(source_file)
            
            # Hedef klasÃ¶rÃ¼ oluÅŸtur
            os.makedirs(os.path.dirname(target_file), exist_ok=True)
            
            # Hedefte dosya var mÄ± kontrol et
            if os.path.exists(target_file):
                source_mtime = os.path.getmtime(source_file)
                target_mtime = os.path.getmtime(target_file)
                
                if source_mtime > target_mtime:
                    # Hedef dosya daha eski, REVISIONS'a taÅŸÄ±
                    revision_folder = self._create_revision_folder(target_path)
                    revision_file = os.path.join(revision_folder, rel_path)
                    
                    # Revision klasÃ¶rÃ¼nÃ¼ oluÅŸtur
                    os.makedirs(os.path.dirname(revision_file), exist_ok=True)
                    
                    # Eski dosyayÄ± taÅŸÄ±
                    shutil.move(target_file, revision_file)
                    stats['files_moved_to_revisions'] += 1
                    stats['size_moved'] += file_size
                    
                    # Yeni dosyayÄ± kopyala
                    shutil.copy2(source_file, target_file)
                    stats['files_copied'] += 1
                    stats['size_copied'] += file_size
                    
                    if self.status_callback:
                        size_str = self.format_size(file_size)
                        self.status_callback(f"âœ“ KopyalandÄ± (eski sÃ¼rÃ¼m arÅŸivlendi): {os.path.basename(source_file)} ({size_str})")
                else:
                    # Dosyalar aynÄ± veya hedef daha yeni, atla
                    stats['files_skipped'] += 1
                    stats['size_skipped'] += file_size
            else:
                # Hedefte dosya yok, direkt kopyala
                shutil.copy2(source_file, target_file)
                stats['files_copied'] += 1
                stats['size_copied'] += file_size
                
                if self.status_callback:
                    size_str = self.format_size(file_size)
                    self.status_callback(f"âœ“ KopyalandÄ± (yeni): {os.path.basename(source_file)} ({size_str})")
        
        return stats
    
    def _create_revision_folder(self, target_path: str) -> str:
        """_REVISIONS klasÃ¶rÃ¼ oluÅŸtur
        
        Args:
            target_path: Hedef klasÃ¶r
            
        Returns:
            Revision klasÃ¶rÃ¼nÃ¼n yolu
        """
        now = datetime.now().strftime('%Y-%m-%d %H-%M')
        revision_folder = os.path.join(target_path, '_REVISIONS', now)
        os.makedirs(revision_folder, exist_ok=True)
        return revision_folder
    
    @staticmethod
    def format_size(size_bytes: int) -> str:
        """Boyutu okunabilir formata Ã§evir
        
        Args:
            size_bytes: Byte cinsinden boyut
            
        Returns:
            FormatlanmÄ±ÅŸ string (Ã¶rn: "1.5 GB", "234 MB")
        """
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.2f} PB"
